import numpy as np
chrs = [str(x) for x in range(1,23)]
chrs.append("X")
units = ["physical", "genetic"]
assembly = ['19', '38'] # genome assemblies
thresh = ['thresh', 'nothresh']

# analyses common to both units. note gene density analysis differs between physical and genetic
#
wvlt_analyses = ["wv","wc_calls", "wc_freq_log10rec","wc_freq_rec","wc_freq_rec_chrs",
					"wc_freq_cds","wc_freq_cds_chrs", "wc_rec_cds", "wc_freq_cdsM","wc_freq_cdsM_chrs",
					 "lm", "wc_freq_B", "wc_freq_B_chrs"]

rule all:
	input:
		expand("wavelet_results/{analysis}_{unit}_hg{n}_{thresh}.txt", analysis = wvlt_analyses, unit=units, n=assembly, thresh='thresh')

rule all_wavelet_inputs:
	input:
		expand("{unit}_windows_hg{n}.bed", unit = units, n = assembly), 
		expand("archaic_freqs_hg{n}/chr{chrom}_frq_{unit}_windows.txt", n = assembly, chrom = chrs, unit = units),
		expand("{unit}_windows_hg{n}.bed", unit = units, n = assembly), 
		expand("gene_density_{unit}_windows_hg{n}.txt", unit = units, n = assembly), 
		expand("B_vals_{unit}_windows_hg{n}.txt", unit = units, n = assembly),
	

rule average_stein_freqs:
	input:
	output:
		"Steinrucken_etal_2018_data/March2018/CEU_lax_chr{chr}/chr{chr}_frqs.txt"
	shell:
		"Rscript --vanilla average_stein_freqs.R {wildcards.chr}"

rule hg38ToHg19:
	input:
		fragments="Skov_etal_2020_data/41586_2020_2225_MOESM3_ESM.txt", # downloaded from Skov et al 2020 supp
		chain="Skov_etal_2020_data/hg38ToHg19.over.chain" # downloaded from UCSC
	output:
		"Skov_etal_2020_data/Skov_fragments_hg19.bed"
	shell: # the awk command prints the chromosome, start and end of each fragment, and a unique identifier column so that new mapped coordinates can be traced to old coordinates. The sed command removes the header. This gives the input to liftOver. 
		""" 
		awk '{print "chr" $1 "\t" $2 "\t" $3 "\t" $1"_"$2"_"$3"_"NR-1}' {intput.fragments} | sed '1d' > Skov_etal_2020_data/Skov_fragments.bed
		liftOver Skov_etal_2020_data/Skov_fragments.bed {input.chain} {output} unMapped
		"""

rule Sank_snps_bed: # This will be input to liftOver
	input:
		snps=expand("Sankararaman_etal_2014_data/summaries.release/snp/chr-{chr}.snp.gz", chr=chrs)
	output:
		"Sankararaman_etal_2014_data/hg19_snps.bed"
	shell:
		"""
		gunzip -c {input} | awk '{print "chr"$2 "\t" $4-1 "\t" $4 "\t" "chr"$2"_"$4}' > {output}
		"""
rule sankHg19ToHg38:
	input:
		snps="Sankararaman_etal_2014_data/hg19_snps.bed",
		chain="hg19ToHg38.over.chain" # downloaded from UCSC
	output:
		"sankHg19ToHg38Snps.bed"
	shell:
		"liftOver {input.snps} {intput.chain} {output} Sankararaman_etal_2014_data/unMapped"

rule Stein_snps_bed: # this will be input to liftOver
	input:
		expand("Steinrucken_etal_2018_data/March2018/CEU_lax_chr{chr}/chr{chr}_frqs.txt", chr=chrs),
	output:
		"Steinrucken_etal_2018_data/March2018/steinHg19Snps.bed"
	shell:
		"""
		cat {input} | awk '{print "chr"$1 "\t" $2-1 "\t" $2 "\t" "chr"$1"_"$2"}' > {output}
		"""

rule steinHg19ToHg38:
	input:
		chain="hg19ToHg38.over.chain", # downloaded from UCSC
		bed="Steinrucken_etal_2018_data/March2018/steinHg19Snps.bed"
	output:
		"Steinrucken_etal_2018_data/March2018/steinHg19ToHg38Snps.bed"
	shell:
		"liftOver {input.bed} {input.chain} {output} Steinrucken_etal_2018_data/unMapped"

rule get_freq_hg38:
	input:
		skov_fragments="Skov_etal_2020_data/41586_2020_2225_MOESM3_ESM.txt",
		sank_calls="Sankararaman_etal_2014_data/summaries.release/CEU.hapmap/summaries/chr-{chr}.thresh-90.length-0.00.gz",
		sank_snps="Sankararaman_etal_2014_data/sankHg19ToHg38Snps.bed",
		stein_calls="Steinrucken_etal_2018_data/March2018/CEU_lax_chr{chr}/chr{chr}_frqs.txt",
		stein_snps="Steinrucken_etal_2018_data/March2018/steinHg19ToHg38Snps.bed", 
		recmap="Halldorsson_etal_2019_data/aau1043_datas3"
	output:
		expand("archaic_freqs_hg38/chr{{chr}}_frq_{unit}_windows.txt",unit=units)
	shell:
		"""
		Rscript --vanilla archaic_freq_1chrom_hg38.R {wildcards.chr} \
				{input.skov_fragments} \
				{input.sank_calls} \
				{input.sank_snps} \
				{input.stein_calls} \
				{input.stein_snps} \
				{input.recmap} 
		"""

rule get_freq_hg19:
	input:
		sank_calls="Sankararaman_etal_2014_data/summaries.release/CEU.hapmap/summaries/chr-{chr}.thresh-90.length-0.00.gz",
		stein_calls="Steinrucken_etal_2018_data/March2018/CEU_lax_chr{chr}/chr{chr}_frqs.txt",
		skov_fragments="Skov_etal_2020_data/41586_2020_2225_MOESM3_ESM.txt",
		skov_loc="Skov_etal_2020_data/Skov_fragments_hg19.bed"
	output:
		expand("archaic_freqs_hg19/chr{{chr}}_frq_{unit}_windows.txt",unit=units)
	shell:
		"""
		Rscript --vanilla archaic_freq_1chrom_hg19.R {wildcards.chr} \
				{input.sank_calls} \
				{input.stein_calls} \
				{input.skov_fragments} \
				{input.skov_loc}
		"""		

rule make_window_beds: # genetic windows also output Morgan distance to be able to merge with frequency files
	input:
		"make_{unit}_windows_bed_hg{n}.R"
	output:
		"{unit}_windows_hg{n}.bed"
	shell:
		"""
		Rscript --vanilla make_{wildcards.unit}_windows_bed_hg{wildcards.n}.R | sort -k1,1 -k2,2n > {output}
		"""

rule gtf_to_bed:
	input:
		"hg{n}.knownGene.gtf"	# obtained from USCS genome browser
	output:
		"hg{n}_CDS.bed"
	shell:
		"gtf2bed < {input} | grep 'CDS' | sort -k1,1 -k2,2n > {output}"

rule calculate_gene_density_physical:
	input:
		A="physical_windows_hg{n}.bed",
		B="hg{n}_CDS.bed"
	output:
		out="gene_density_physical_windows_hg{n}.txt",
	shell: # this gets the number of coding base pairs per window
		"""
		bedtools coverage -a {input.A} -b {input.B} | cut -f1-3,5 |\
		sort -k1,1 -k2,2n > {output.out}
		"""

rule calculate_gene_density_genetic:
	input:
		A="genetic_windows_hg{n}.bed",
		B="hg{n}_CDS.bed"
	output:
		out="gene_density_genetic_windows_hg{n}.txt",
	shell:
		# for genetic windows kept Morgan for id so there's an extra col in output
		"""
		bedtools coverage -a {input.A} -b {input.B} | cut -f1-4,6 |\
		sort -k1,1 -k2,2n > {output.out}
		"""

rule windowed_B_values:	
	input:
		A="{unit}_windows_hg{n}.bed",
		B="B_values/hg{n}/bstat_hg{n}_v2_sorted.txt"
	output:
		"B_vals_{unit}_windows_hg{n}.txt"
	shell:
		"""
		bedmap --echo --delim "\t" --wmean --sci {input.A} {input.B} > {output}
		"""

rule run_wavelets:
	input:
		"gene_density_{unit}_windows_hg{n}.txt",
		"B_vals_{unit}_windows_hg{n}.txt",
		expand("archaic_freqs_hg{n}/chr{chr}_frq_{{unit}}_windows.txt",chr=chrs,unit=units, n=assembly)	
	output:
		"wavelet_results/{analysis}_{unit}_hg{n}_{thresh}.txt"
	shell:
		"""
		Rscript --vanilla wavelet_analyses.R {wildcards.unit} {wildcards.analysis} hg{wildcards.n} {wildcards.thresh}
		"""

